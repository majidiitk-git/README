{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD-FS3PaxMTj"
      },
      "source": [
        "# Mount the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZGEQfaSgGTq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uKhWYfd0tkO"
      },
      "source": [
        "# Access Gene expression omnibus (GEO) data (GSE84422 with plateform ID GPL96), already downloaded in Google Drive\n",
        "\n",
        "Access the data from Google Drive downloaded previously\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUIWDo_LXy7T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "expr_df = pd.read_csv(\"/content/drive/MyDrive/Gene_Exp_Data.csv\", index_col=0)\n",
        "print(\"Expression matrix shape:\", expr_df.shape)\n",
        "expr_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot1h-ghanIgz"
      },
      "source": [
        "The above file has been uploaded to Google Drive and is ready for AI and ML use. Now we will not run the above codes. We will only remount the drive if needed, add the necessary libraries, define the file path, and use the data as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_31iCWrZTI3"
      },
      "source": [
        "# Box plot of GEO Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i5X0R8-ej1F"
      },
      "source": [
        "Plot few samples only, to reduce the execution time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plPkqbFch7lH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load expression data with probe IDs as index\n",
        "expr_df = pd.read_csv(\"/content/drive/MyDrive/Gene_Exp_Data.csv\", index_col=0)\n",
        "\n",
        "# Transpose: rows = samples, columns = probes\n",
        "df_t = expr_df.transpose()\n",
        "\n",
        "# Keep only first 20 samples (i.e., first 20 rows)\n",
        "df_t_subset = df_t.iloc[:20]\n",
        "\n",
        "# Plot boxplot: one box per sample\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_t_subset.transpose().boxplot(\n",
        "    rot=45,\n",
        "    grid=False,\n",
        "    showfliers=False\n",
        ")\n",
        "plt.title(\"Boxplot of First 20 Samples - GSE84422 GPL96\")\n",
        "plt.ylabel(\"Expression (log2 scale)\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaS4RppNi5MW"
      },
      "source": [
        "The above graph tells that :\n",
        "The spread and center of expression values across samples look quite similar.\n",
        "\n",
        "This suggests no major normalization issues or technical outliers in the first 20 samples.\n",
        "\n",
        "The boxes are nearly aligned, meaning gene expression distribution is comparable across samples which is a a good sign."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR1hTrhrjwjK"
      },
      "source": [
        "Plot for all samples in GEO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnpYTwwsh7Ph"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_path = '/content/drive/MyDrive/GSE84422_GPL96_expression_data.csv'\n",
        "# Load expression data with probe IDs as index\n",
        "expression_data = pd.read_csv(file_path, index_col=0)\n",
        "\n",
        "# Transpose: rows = samples, columns = probes\n",
        "df_t = expression_data.transpose()\n",
        "\n",
        "# Keep only first 20 samples (i.e., first 20 rows)\n",
        "#df_t_subset = df_t.iloc[:20]\n",
        "\n",
        "# Plot boxplot: one box per sample\n",
        "plt.figure(figsize=(500, 6))\n",
        "df_t.transpose().boxplot(\n",
        "    rot=45,\n",
        "    grid=False,\n",
        "    showfliers=False\n",
        ")\n",
        "plt.title(\"Boxplot of all Samples - GSE84422 GPL96\")\n",
        "plt.ylabel(\"Expression (log2 scale)\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrxpxtshrhZW"
      },
      "source": [
        "# Expression density plot Gene Exp Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULar69B2vMrH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Transpose so that each sample (column) is plotted\n",
        "for sample in expr_df.columns:\n",
        "    sns.kdeplot(expr_df[sample], linewidth=0.5)\n",
        "\n",
        "plt.title(\"GSE84422: Expression density\")\n",
        "plt.xlabel(\"Intensity\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qs0h2jdridc"
      },
      "source": [
        "# Mean variation trend plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWd1UlFHrpDd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load expression data: rows = genes/probes, columns = samples\n",
        "# Data is already log2-transformed!\n",
        "# expression_data = pd.read_csv(\"expression_data.csv\", index_col=0)\n",
        "# Load the expression and metadata CSVs\n",
        "file_path = '/content/drive/MyDrive/GSE84422_GPL96_expression_data.csv'\n",
        "expression_data = pd.read_csv(file_path, index_col=0) # Load with ID_REF as index\n",
        "# Calculate average log-expression (mean) and standard deviation (sigma)\n",
        "mean_log_expr = expression_data.mean(axis=1)\n",
        "std_log_expr = expression_data.std(axis=1)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(mean_log_expr, std_log_expr, s=1, color='black', alpha=0.6)\n",
        "plt.title(\"GSE84422 : Mean-variance trend\")\n",
        "plt.xlabel(\"Average log-expression\")\n",
        "plt.ylabel(\"sqrt(sigma)\")\n",
        "plt.text(mean_log_expr.max()-1, std_log_expr.max()-0.1, f\"{expression_data.shape[0]} probes\", fontsize=10)\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1kMT-O41E6p"
      },
      "source": [
        "# UMAP Plot of Dataset\n",
        "UMAP plot for entire sample without any grouping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pycGdXi1GEG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import umap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# The'expression_data' is the DataFrame with genes as rows and samples as columns\n",
        "# and it is already loaded (and optionally filtered)\n",
        "\n",
        "# Transpose so samples are rows and genes are features\n",
        "data_t = expr_df.T\n",
        "data_t.head()\n",
        "# Scale the data\n",
        "scaled_data = StandardScaler().fit_transform(data_t)\n",
        "\n",
        "# UMAP with 15 neighbors\n",
        "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
        "embedding = reducer.fit_transform(scaled_data)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(embedding[:, 0], embedding[:, 1], s=30, c='teal')\n",
        "plt.title(\"GSE84422/GPL96: UMAP(nbrs=15)\")\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAJXptCAnGtw"
      },
      "source": [
        "# UMAP Clustering for disease status\n",
        "\n",
        "UMAP for neuropathological category (seems not a good cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGXWlK_1nNhj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the expression and metadata CSVs\n",
        "file_path = '/content/drive/MyDrive/GSE84422_GPL96_expression_data.csv'\n",
        "expr_df = pd.read_csv(file_path, index_col=0) # Load with ID_REF as index\n",
        "\n",
        "# Load the metadata file saved previously\n",
        "meta_df = pd.read_csv(\"/content/drive/MyDrive/geo_accession_and_all_characteristics.csv\")\n",
        "\n",
        "# Transpose expression data so samples are rows and genes are features\n",
        "expr_df_T = expr_df.T\n",
        "\n",
        "# Check sample names in both dataframes\n",
        "print(\"Expression data samples (first 5):\", expr_df.index[:5].tolist())\n",
        "print(\"Metadata geo_accession (first 5):\", meta_df['geo_accession'][:5].tolist())\n",
        "\n",
        "# Align metadata with expression data using 'geo_accession'\n",
        "# Assuming 'geo_accession' column in meta_df contains the sample names (GSM IDs)\n",
        "meta_df = meta_df.set_index('geo_accession')\n",
        "\n",
        "# Print indices after setting index\n",
        "print(\"Expression data index (first 5):\", expr_df_T.index[:5].tolist())\n",
        "print(\"Metadata index (first 5):\", meta_df.index[:5].tolist())\n",
        "\n",
        "\n",
        "# Check for samples in expression data not in metadata\n",
        "missing_samples = expr_df_T.index.difference(meta_df.index)\n",
        "if len(missing_samples) > 0:\n",
        "    print(f\"Warning: {len(missing_samples)} samples in expression data not found in metadata:\", missing_samples.tolist())\n",
        "\n",
        "# Filter expression data to keep only samples present in metadata\n",
        "expr_df_T_aligned = expr_df_T.loc[meta_df.index.intersection(expr_df_T.index)]\n",
        "meta_df_aligned = meta_df.loc[expr_df_T_aligned.index]\n",
        "\n",
        "# Standardize expression data before UMAP\n",
        "scaled_data = StandardScaler().fit_transform(expr_df_T_aligned)\n",
        "\n",
        "# Apply UMAP\n",
        "reducer = umap.UMAP(random_state=42)\n",
        "embedding = reducer.fit_transform(scaled_data)\n",
        "\n",
        "# Extract the 'neuropathological category' for coloring\n",
        "ad_status = meta_df_aligned['neuropathological category']\n",
        "\n",
        "# Plot UMAP with colors based on 'neuropathological category'\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=ad_status.astype('category').cat.codes, cmap='Set1', s=50)\n",
        "plt.title(\"GSE84422/GPL96: UMAP Projection Colored by Neuropathological Category\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "\n",
        "# Add legend\n",
        "handles, labels = scatter.legend_elements()\n",
        "legend_labels = ad_status.astype('category').cat.categories\n",
        "plt.legend(handles, legend_labels, title=\"Neuropathological Category\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FTRRoVfDcXd"
      },
      "source": [
        "# Phenotype (Meta data access)\n",
        "\n",
        "\n",
        "\n",
        "Phenotype (metadata) data access from previous notebook (GEO84422.IPYNB), 84422,96\n",
        "\n",
        "\n",
        " saved file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbtnHG4ZDb9_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the metadata file\n",
        "meta_df.to_csv('/content/drive/MyDrive/geo_accession_and_all_characteristics.csv', index=False)\n",
        "\n",
        "# Display result\n",
        "print(\" Metadata shape shape:\", meta_df.shape)\n",
        "meta_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkBae5TC2H3M"
      },
      "source": [
        "Study of metadata properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emfvz3Nrk5_d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "meta_df = pd.read_csv(\"/content/drive/MyDrive/geo_accession_and_all_characteristics.csv\")\n",
        "meta_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUh9mA1ahoBa"
      },
      "source": [
        "# Gene exp data extraction for Volcano plot: differential expression analysis (DEA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhvDpSjjhrQQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# extract desirable column in a single file\n",
        "#merged = pd.concat([table_A['x'], table_B['y']], axis=1)\n",
        "meta_df = pd.read_csv(\"/content/drive/MyDrive/geo_accession_and_all_characteristics.csv\")\n",
        "# meta_df_T = meta_df.T\n",
        "meta_df.head(10)\n",
        "# print(meta_df_T.head(10))\n",
        "expr_df = pd.read_csv(\"/content/drive/MyDrive/Gene_Exp_Data.csv\", index_col=0)\n",
        "# expression_data = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_expression_data.csv\", index_col=0) # Load with ID_REF as index\n",
        "expr_df_T = expr_df.T\n",
        "# expr_df_T.head()\n",
        "# print(expression_data.head())\n",
        "#data_volc = meta_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5psBPcN4YWQ"
      },
      "source": [
        "Print different disease status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhz8IbfdlvOF"
      },
      "outputs": [],
      "source": [
        "# Print 9th column (AD status from metadata)\n",
        "meta_df_T = meta_df.T\n",
        "Category_AD = meta_df_T.iloc[9]\n",
        "print(Category_AD)\n",
        "# Assign new column names\n",
        "# expression_data.columns = new_headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3lBi97F70fl"
      },
      "outputs": [],
      "source": [
        "# expression_data_T.index = Category_AD\n",
        "# expression_data_T.to_csv('/content/drive/MyDrive/GSE84422_GPL96_DEA_data.csv')\n",
        "# expression_data_T.head()\n",
        "\n",
        "expr_df_T.index = Category_AD\n",
        "expr_df_T.to_csv('/content/drive/MyDrive/GSE84422_GPL96_DEA_data.csv')\n",
        "expr_df_T.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD37ou5KgaCS"
      },
      "outputs": [],
      "source": [
        "print(expr_df_T.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pqdRww89MZB"
      },
      "outputs": [],
      "source": [
        "DEA_data = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_DEA_data.csv\")\n",
        "print(\"DEA_data\", DEA_data.shape)\n",
        "DEA_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwTBjfRSSNwh"
      },
      "outputs": [],
      "source": [
        "DEA_data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRXVVA_FIKou"
      },
      "source": [
        "# Extracrting Data for Normal and definite AD status only\n",
        "\n",
        "Normal vs definite Differential Expression analysis DEA (Volcano plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZAmMnPVTsEF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "DEA_data = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_DEA_data.csv\", index_col=0)\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/FILENAME.csv\", index_col=0)\n",
        "# Keep only samples from 'Normal' and 'Definite AD'\n",
        "DEA_filter_AD = DEA_data[DEA_data.index.isin(['Normal', 'definite AD'])]\n",
        "DEA_filter_AD.to_csv(\"/content/drive/MyDrive/DEA_filter_AD.csv\")\n",
        "\n",
        "DEA_filter_AD.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUgpdF2VgFdQ"
      },
      "outputs": [],
      "source": [
        "print(DEA_filter_AD.shape)\n",
        "# now only 542 sample are only Definite of normal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJpjin6u5ZkG"
      },
      "source": [
        "Find transpose of Gene Exp Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ1M_HfbuQuL"
      },
      "outputs": [],
      "source": [
        "# This format (transpose) is needed for applying the t-test gene by gene\n",
        "DEA_filter_AD_T = DEA_filter_AD.T\n",
        "\n",
        "print(DEA_filter_AD_T)\n",
        "DEA_filter_AD.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ4-Yx3hvHQF"
      },
      "source": [
        "# Creating lables for disease status\n",
        "\n",
        " Create labels for  two groups\n",
        " 0 for normal, 1 for definite AD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2Lq5nIsvMH7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "group_labels = DEA_filter_AD.index.values  # ['Normal', 'Normal', 'definite AD', ...]\n",
        "# print(group_labels)\n",
        "labels = np.array([1 if g == 'definite AD' else 0 for g in group_labels])\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-YEJVWQXFvU"
      },
      "outputs": [],
      "source": [
        "DEA_filter_AD_T.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbK3Wm2W-QpV"
      },
      "source": [
        "# Finding p_values and fold change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA8kWeM2ygme"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "p_values = []\n",
        "logFC = []\n",
        "\n",
        "for gene in DEA_filter_AD_T.index:\n",
        "    group1 = DEA_filter_AD_T.loc[gene, labels == 0]\n",
        "    #expression values of one gene across Normal samples.\n",
        "    group2 = DEA_filter_AD_T.loc[gene, labels == 1]\n",
        " #group2 selects the row(s) for gene from DEA_filter_AD_T and keeps only the columns where labels equals 1.\n",
        " # the above code are iteration based, hence storing values as PanadaSeries (not data frame)\n",
        " # printing head results in one series\n",
        "\n",
        "    mean1 = group1.mean()\n",
        "    mean2 = group2.mean()\n",
        "#by default computes the mean column-wise (axis=0).\n",
        "\n",
        "\n",
        "    # logFC.append(np.log2(mean2 + 1e-6) - np.log2(mean1 + 1e-6))  # already log2 transformed\n",
        "    logFC.append(mean2 - mean1)\n",
        "\n",
        "    t_stat, p_val = ttest_ind(group1, group2, equal_var=False)\n",
        "    p_values.append(p_val)\n",
        "\n",
        "\n",
        "print(mean1.shape)\n",
        "print(mean2.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEqFO7pl_myf"
      },
      "source": [
        "Showing the p_values and logFC for each gene\n",
        "\n",
        "coding for dea_results_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hco50jqt9KJl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "results = []  # to store results for each gene\n",
        "\n",
        "for gene in DEA_filter_AD_T.index:\n",
        "    group1 = DEA_filter_AD_T.loc[gene, labels == 0]  # Normal\n",
        "    group2 = DEA_filter_AD_T.loc[gene, labels == 1]  # Definite AD\n",
        "\n",
        "    mean1 = group1.mean()\n",
        "    mean2 = group2.mean()\n",
        "\n",
        "    log_fc = mean2 - mean1  # already log2 transformed\n",
        "    t_stat, p_val = ttest_ind(group1, group2, equal_var=False)\n",
        "\n",
        "    results.append([gene, mean1, mean2, log_fc, p_val])\n",
        "\n",
        "# Create DataFrame\n",
        "dea_results_new = pd.DataFrame(results, columns=[\"Gene\", \"Mean_Normal\", \"Mean_DefiniteAD\", \"log2FC\", \"p_value\"])\n",
        "\n",
        "# Optional: sort by p-value\n",
        "# dea_results = dea_results.sort_values(by=\"p_value\")\n",
        "\n",
        "# View top rows\n",
        "print(dea_results_new.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d02kw09qz8k8"
      },
      "outputs": [],
      "source": [
        "print(mean2.shape)\n",
        "#Saving as DataFrame\n",
        "\n",
        "# dea_results.to_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD.csv\", index=False)\n",
        "# print(mean1.shape)\n",
        "# print(mean2.shape)\n",
        "DEA_filter_AD_T.loc[:, labels == 0].head()\n",
        "# group1_T = group1.T\n",
        "# print(group2.head())\n",
        "# print(group1.shape)\n",
        "# print(group2.shape)\n",
        "# group1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqHmUGtKAOpT"
      },
      "source": [
        "Sorting based on values calculated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HgSP3OIb8Np"
      },
      "outputs": [],
      "source": [
        "# Sort by p-value for FDR correction\n",
        "\n",
        "# dea_results_new = dea_results_new.sort_values('p_value').reset_index(drop=True)\n",
        "\n",
        "# Benjamini-Hochberg adjustment\n",
        "n = len(dea_results_new)\n",
        "dea_results_new['adj_pval'] = dea_results_new['p_value'] * n / (np.arange(1, n+1))\n",
        "dea_results_new['adj_pval'] = dea_results_new['adj_pval'].clip(upper=1)  # p-values can't exceed 1\n",
        "\n",
        "# Add -log10 p-value for volcano plot\n",
        "dea_results_new['-log10(pval)'] = -np.log10(dea_results_new['p_value'])\n",
        "\n",
        "# Save to CSV\n",
        "dea_results_new.to_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD_new.csv\", index=False)\n",
        "\n",
        "\n",
        "# View first few rows\n",
        "print(dea_results_new.head(10))\n",
        "\n",
        "# Originally, 1007_s_at was just first in the index order (probably from the raw GEO file order).\n",
        "# After sorting, genes with strongest statistical significance (lowest p_value,or highest FDR) are moved to the top, that is why we now see 214414_x_at instead.\n",
        "dea_results_new[dea_results_new['Gene'] == '1007_s_at']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O93lcQV1v73"
      },
      "source": [
        "Saving the results obtained by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKyQSGZG14b3"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# dea_results = pd.DataFrame({\n",
        "#     'Gene': DEA_filter_AD_T.index,\n",
        "#     'log2FC': logFC,\n",
        "#     'p_value': p_values\n",
        "# })\n",
        "\n",
        "# dea_results.to_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD.csv\", index=False)\n",
        "# # print(dea_results.head())\n",
        "\n",
        "\n",
        "# # Adjust p-values using Benjamini-Hochberg (FDR)\n",
        "# dea_results['adj_pval'] = dea_results['p_value'] * len(dea_results) / (np.arange(1, len(dea_results)+1))\n",
        "# dea_results = dea_results.sort_values('p_value')\n",
        "# dea_results['-log10(pval)'] = -np.log10(dea_results['p_value'])\n",
        "# dea_results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_liZiwLa80Fu"
      },
      "source": [
        "# Volcano plot from the values obtained above\n",
        "\n",
        "Volcano plot using dea_results_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub4bvmsV82bH"
      },
      "outputs": [],
      "source": [
        "!pip install adjustText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySw3Lbw9I-Kz"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "import pandas as pd\n",
        "dea_results_new = pd.read_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD_new.csv\")\n",
        "# dea_results_new.head(10)\n",
        "# Sort by p-value to get top 10 significant genes\n",
        "dea_results_new.sort_values('p_value').head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_nGS64N-0eD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from adjustText import adjust_text\n",
        "\n",
        "\n",
        "\n",
        "dea_results_new = pd.read_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD_new.csv\")\n",
        "\n",
        "# Sort by p-value to get top 10 significant genes\n",
        "# top10 = dea_results_new.sort_values('p_value').head(10)\n",
        "# Filter for significance and effect size\n",
        "filtered = dea_results_new[\n",
        "    (abs(dea_results_new['log2FC']) > 0.5) &\n",
        "    (dea_results_new['adj_pval'] < 0.05)\n",
        "]\n",
        "\n",
        "\n",
        "print(filtered)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(dea_results_new['log2FC'],\n",
        "            dea_results_new['-log10(pval)'],\n",
        "            color='blue',\n",
        "            # c=(dea_results_new['adj_pval'] < 0.05),\n",
        "            cmap='coolwarm',\n",
        "            alpha=0.7\n",
        ")\n",
        "###################\n",
        "# Highlight DEGs\n",
        "plt.scatter(filtered['log2FC'], filtered['-log10(pval)'],\n",
        "            color='red', alpha=0.8, label='|log2FC|>0.5 & FDR<0.05')\n",
        "##################\n",
        "\n",
        "plt.axhline(-np.log10(0.05), color='grey', linestyle='--') # -Log10(0.05) = 1.3, p = 0.05)\n",
        "plt.axvline(0.5, color='green', linestyle='--')\n",
        "plt.axvline(-0.5, color='green', linestyle='--')\n",
        "\n",
        "# Label top 10 significant genes\n",
        "\n",
        "# Use filtered genes instead of top10\n",
        "texts = []\n",
        "for _, row in filtered.iterrows():\n",
        "    texts.append(\n",
        "        plt.text(\n",
        "            row['log2FC'],\n",
        "            row['-log10(pval)'],\n",
        "            row['Gene'],  # or row['Gene Symbol'] if merged with annotation\n",
        "            fontsize=8,\n",
        "            ha='center',\n",
        "            va='bottom'\n",
        "        )\n",
        "    )\n",
        "# Adjust text to avoid overlap\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='black'))\n",
        "plt.title(\"Volcano Plot: Definite AD vs Normal \")\n",
        "plt.xlabel(\"log2(Fold Change)\")\n",
        "plt.ylabel(\"-log10(p-value)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9U5Jjy79-JW"
      },
      "source": [
        "**Useful Deatils of Volcano plots:**\n",
        "\n",
        "Axes:\n",
        "X-axis (log2(Fold Change)):\n",
        "Measures the magnitude and direction of change.\n",
        "Left (−): Downregulated genes in Definite AD.\n",
        "Right (+): Upregulated genes in Definite AD.\n",
        "Vertical green lines at ±1 show 2-fold change thresholds.\n",
        "Y-axis (−log10(p-value)):\n",
        "Measures statistical significance.\n",
        "The higher the point, the smaller the p-value (i.e., more significant).\n",
        "The horizontal dashed line typically marks p = 0.05 → −log10(0.05) ≈ 1.3.\n",
        "\n",
        "**Points:**\n",
        "Red dots: Genes with p-value < 0.05\n",
        "Blue dots: Genes with p-value ≥ 0.05\n",
        "Only the red dots outside the green vertical lines are both:\n",
        "Statistically significant (p < 0.05), and\n",
        "Biologically significant (|log2FC| > 1)\n",
        "These are your most interesting differentially expressed genes (DEGs).\n",
        "\n",
        "**Points:**\n",
        "Red dots: Genes with p-value < 0.05\n",
        "Blue dots: Genes with p-value ≥ 0.05\n",
        "Only the red dots outside the green vertical lines are both:\n",
        "Statistically significant (p < 0.05), and\n",
        "Biologically significant (|log2FC| > 1)\n",
        "These are the most interesting differentially expressed genes (DEGs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWKvIX-YiFTk"
      },
      "outputs": [],
      "source": [
        "dea_results_new.to_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD_new.csv\", index=False)\n",
        "print(\"Max log2FC:\", dea_results_new[\"log2FC\"].max())\n",
        "print(\"Min log2FC:\", dea_results_new[\"log2FC\"].min())\n",
        "print(\"Max -log10(p-value):\", (-np.log10(dea_results_new[\"p_value\"])).max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fENAAFny-GD3"
      },
      "source": [
        "Annotation data for Probe ID, Gene Symbol, and others.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRIpZokaBihs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read uploaded file with some changes\n",
        "annotation_data = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/GPL96-57554_annot.txt\",\n",
        "    sep='\\t',\n",
        "    comment='#'\n",
        ")\n",
        "\n",
        "# Save file with another name (without index column)\n",
        "annotation_data.to_csv(\n",
        "    \"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "# If want it later, load it as 'annot':\n",
        "# annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhaELleiTbYF"
      },
      "outputs": [],
      "source": [
        "# Load the saved annotation file\n",
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "annot_prob_Gene_ID = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "print(annot_prob_Gene_ID.head(20))\n",
        "# Display the top 20 rows\n",
        "# print(annot.head(20))\n",
        "annot[annot['ID'] == '204151_x_at']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YLKpDfJT7GY"
      },
      "outputs": [],
      "source": [
        "print(annot_prob_Gene_ID.tail(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0ER8pshFDhK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "expr_df = pd.read_csv(\"/content/drive/MyDrive/Gene_Exp_Data.csv\", index_col=0)\n",
        "# expression_data = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_expression_data.csv\", index_col=0)\n",
        "print(\"Expression matrix shape:\", expr_df.shape)\n",
        "expr_df.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "217A-e-wTNC1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "# annot_prob_Gene_ID = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "\n",
        "dea_results_new = pd.read_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD_new.csv\")\n",
        "# Merge DEA results with annotation data after mapping\n",
        "merged = dea_results_new.merge(annot, left_on=\"Gene\", right_on=\"ID\", how=\"left\")\n",
        "\n",
        "# Keep only genes that meet the thresholds\n",
        "filtered_merged = merged[\n",
        "    (abs(merged['log2FC']) > 0.5) &\n",
        "    (merged['adj_pval'] < 0.05)\n",
        "]\n",
        "# \"ENTREZ_GENE_ID\"\n",
        "# Print the filtered merged data\n",
        "print(filtered_merged[['Gene', 'Gene Symbol','ENTREZ_GENE_ID', 'log2FC', 'p_value', 'adj_pval']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9_gw5iED2Jc"
      },
      "source": [
        "Remove only duplicate genes AND KEEP IMP DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLnkiqYUEFEz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "# annot_prob_Gene_ID = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "\n",
        "dea_results_new = pd.read_csv(\"/content/drive/MyDrive/DEA_Normal_vs_DefiniteAD_new.csv\")\n",
        "# Merge DEA results with annotation data after mapping\n",
        "merged = dea_results_new.merge(annot, left_on=\"Gene\", right_on=\"ID\", how=\"left\")\n",
        "\n",
        "# Keep only genes that meet the thresholds\n",
        "filtered_merged = merged[\n",
        "    (abs(merged['log2FC']) > 0.5) &\n",
        "    (merged['adj_pval'] < 0.05)\n",
        "]\n",
        "# \"ENTREZ_GENE_ID\"\n",
        "# Print the filtered merged data\n",
        "# print(filtered_merged)\n",
        "# print(filtered_merged[['Gene Symbol','ENTREZ_GENE_ID', 'log2FC', 'p_value', 'adj_pval']])\n",
        "\n",
        "# Remove duplicate genes based on 'Gene Symbol'\n",
        "filtered_unique = filtered_merged.drop_duplicates(subset=['Gene Symbol'], keep='first')\n",
        "\n",
        "# Display the cleaned dataframe\n",
        "filtered_unique_all_data = filtered_unique[['Gene Symbol', 'ENTREZ_GENE_ID', 'log2FC', 'p_value', 'adj_pval']]\n",
        "print(filtered_unique_all_data)\n",
        "#sig_genes_df.to_csv('/content/drive/MyDrive/signi_genes.csv', index=False)\n",
        "filtered_unique_all_data.to_csv('/content/drive/MyDrive/filtered_unique_all_data.csv', index=False)\n",
        "# sig_genes_all_info = filtered_merged[['Gene Symbol','ENTREZ_GENE_ID', 'log2FC', 'p_value', 'adj_pval']].dropna().unique().tolist()\n",
        "# print(sig_genes_all_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grXnEM_tcX5v"
      },
      "source": [
        "List of signifcant genes obtained from DEA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BcCfUbW2GTd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Use Gene Symbol column, drop duplicates & NaN\n",
        "sig_genes = filtered_merged['Gene Symbol'].dropna().unique().tolist()\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "sig_genes_df = pd.DataFrame(sig_genes, columns=[\"Gene Volcano\"])\n",
        "\n",
        "# Save to CSV in drive\n",
        "sig_genes_df.to_csv('/content/drive/MyDrive/signi_genes.csv', index=False)\n",
        "# meta_df.to_csv('/content/drive/MyDrive/geo_accession_and_all_characteristics.csv', index=False)\n",
        "print(\"Significant genes saved to drive as 'signi_genes'.csv'\")\n",
        "\n",
        "print(f\"Number of significant genes: {len(sig_genes)}\")\n",
        "print(sig_genes)  # Preview first 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgPKM68YOTM-"
      },
      "source": [
        "# UMAP plot for Normal and definite AD only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyggwz9LqVZg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load expression and metadata\n",
        "expr_df = pd.read_csv('/content/drive/MyDrive/GSE84422_GPL96_expression_data.csv', index_col=0)\n",
        "meta_df = pd.read_csv(\"/content/drive/MyDrive/geo_accession_and_all_characteristics.csv\")\n",
        "\n",
        "# Transpose expression data (samples as rows)\n",
        "expr_df_T = expr_df.T\n",
        "\n",
        "# Set geo_accession as index\n",
        "meta_df = meta_df.set_index('geo_accession')\n",
        "\n",
        "# Align expression with metadata\n",
        "expr_df_T_aligned = expr_df_T.loc[expr_df_T.index.intersection(meta_df.index)]\n",
        "meta_df_aligned = meta_df.loc[expr_df_T_aligned.index]\n",
        "\n",
        "# Filter only Normal and Definite AD samples\n",
        "mask = meta_df_aligned['neuropathological category'].isin(['Normal', 'Definite AD'])\n",
        "expr_df_filtered = expr_df_T_aligned[mask]\n",
        "meta_df_filtered = meta_df_aligned[mask]\n",
        "\n",
        "# Highlighting expression of 17 significant genes\n",
        "\n",
        "# List of 17 significant genes (probe IDs from volcano plot, replace with actual if different)\n",
        "sig_genes = [\n",
        "    \"202912_at\", \"202917_s_at\", \"203535_at\", \"203915_at\", \"204018_x_at\", \"204712_at\",\n",
        "    \"205048_s_at\", \"205230_at\", \"207574_s_at\", \"208151_x_at\", \"208719_s_at\", \"209047_at\",\n",
        "    \"209116_x_at\", \"209183_s_at\", \"210512_s_at\", \"211696_x_at\", \"213479_at\"\n",
        "]\n",
        "\n",
        "# Check which of these genes are in the expression data\n",
        "available_genes = [g for g in sig_genes if g in expr_df_filtered.columns]\n",
        "missing_genes = list(set(sig_genes) - set(available_genes))\n",
        "print(f\"Missing genes: {missing_genes}\")\n",
        "\n",
        "# Calculate average expression per sample for significant genes\n",
        "sig_expr = expr_df_filtered[available_genes]\n",
        "avg_sig_expr = sig_expr.mean(axis=1)\n",
        "\n",
        "# Scale expression data\n",
        "scaled_data = StandardScaler().fit_transform(expr_df_filtered)\n",
        "\n",
        "# Apply UMAP\n",
        "reducer = umap.UMAP(random_state=42)\n",
        "embedding = reducer.fit_transform(scaled_data)\n",
        "\n",
        "# Plot with color representing average expression of significant genes\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=avg_sig_expr, cmap='viridis', s=50)\n",
        "plt.title(\"UMAP (Normal vs Definite AD) - Colored by Avg Expression of 17 Significant Genes\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "cbar = plt.colorbar(scatter)\n",
        "cbar.set_label(\"Avg Expression (17 genes)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LlO12X_qBMV"
      },
      "outputs": [],
      "source": [
        "# ACCESS SIGNIFICANT GENES\n",
        "sig_genes = pd.read_csv(\"/content/drive/MyDrive/signi_genes.csv\")\n",
        "sig_genes_df = pd.DataFrame(sig_genes, columns=[\"Gene Volcano\"])\n",
        "# print(sig_genes)\n",
        "print(sig_genes_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyKdahOaxTRu"
      },
      "source": [
        "# Random forest analysis\n",
        "To find rank list of the genes using random forest, and then finding intersection of genes with Volcano Genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D19c6nKHvjss"
      },
      "outputs": [],
      "source": [
        "# DEA_data = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_DEA_data.csv\", index_col=0)\n",
        "# # df = pd.read_csv(\"/content/drive/MyDrive/FILENAME.csv\", index_col=0)\n",
        "# # Keep only samples from 'Normal' and 'Definite AD'\n",
        "# DEA_filter_AD = DEA_data[DEA_data.index.isin(['Normal', 'definite AD'])]\n",
        "# DEA_filter_AD.to_csv(\"/content/drive/MyDrive/DEA_filter_AD.csv\")\n",
        "\n",
        "# DEA_filter_AD.head()\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# -------------------------------\n",
        "# 1. Load data\n",
        "# -------------------------------\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/DEA_filter_AD.csv\", index_col=0)\n",
        "\n",
        "# Separate labels (first column) and features (all gene columns)\n",
        "y = data.index   # 'Normal' or 'definite AD'\n",
        "X1 = data.values  # all gene expression values #unfiltered\n",
        "\n",
        "##############################################################\n",
        "\n",
        "gene_names = data.columns\n",
        "\n",
        "print(\"Initial dataset size:\", X1.shape)  # (samples, genes)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Filter low-variance genes\n",
        "# -------------------------------\n",
        "# This removes genes with very low variance\n",
        "selector = VarianceThreshold(threshold=0.0)  # adjust threshold if needed\n",
        "X = selector.fit_transform(X1)\n",
        "filtered_gene_names = gene_names[selector.get_support()]\n",
        "\n",
        "print(\"Dataset size after filtering:\", X.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Train-test split\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "#############################################################\n",
        "# -------------------------------\n",
        "# 2. Train-test split\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "# 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 252\n",
        "# -------------------------------\n",
        "# 3. Train Random Forest\n",
        "# -------------------------------\n",
        "# rf = RandomForestClassifier(\n",
        "#     n_estimators=100,\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1,\n",
        "#     class_weight=\"balanced\"\n",
        "# )\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=252,\n",
        "    random_state=42,\n",
        "    min_samples_leaf = 4,\n",
        "    min_samples_split = 10,\n",
        "    n_jobs=-1,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate\n",
        "# -------------------------------\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Feature importance\n",
        "# -------------------------------\n",
        "importances = rf.feature_importances_\n",
        "gene_names = data.columns  # gene IDs from columns\n",
        "\n",
        "gene_importances = pd.DataFrame({\n",
        "    \"Gene\": gene_names,\n",
        "    \"Importance\": importances\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(gene_importances)\n",
        "# 6. Load annotation and merge\n",
        "# -------------------------------\n",
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "\n",
        "# Keep only relevant columns\n",
        "annot = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "# So after this line, annot is a slimmed-down dataframe with just these three columns.\n",
        "# The merge is done with:\n",
        "# left_on=\"Gene\" → use the \"Gene\" column from gene_importances\n",
        "# right_on=\"ID\" → match with \"ID\" column from annot\n",
        "# how=\"left\" → keep all rows from gene_importances even if some genes don’t have a matching annotation. For those without a match, the \"Gene Symbol\" and \"ENTREZ_GENE_ID\" will be NaN.\n",
        "importance_annot = gene_importances.merge(\n",
        "    annot,\n",
        "    left_on=\"Gene\",   # from gene_importances\n",
        "    right_on=\"ID\",    # from annotation\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Save results\n",
        "importance_annot.to_csv(\"/content/drive/MyDrive/gene_ranking_randomforest.csv\", index=False)\n",
        "\n",
        "print(\"Top 50 important genes:\")\n",
        "print(importance_annot.head(50))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frM3bO5IAVfG"
      },
      "source": [
        "Hyper parameter tuning to refine the results from Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG4rsEFx9pGB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import randint\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/DEA_filter_AD.csv\", index_col=0)\n",
        "\n",
        "# Separate labels (first column) and features (all gene columns)\n",
        "y = data.index   # 'Normal' or 'definite AD'\n",
        "X = data.values  # all gene expression values #unfiltered\n",
        "# -------------------------------\n",
        "# 1. Split Data\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "# -------------------------------\n",
        "# 2. Define Hyperparameter Space\n",
        "# -------------------------------\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    # 'max_depth': randint(1, 5)  # 'None' is not added\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    # \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "    # \"bootstrap\": [True, False]\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Randomized Search\n",
        "# -------------------------------\n",
        "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\", n_jobs=-1)\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=5,              # try 10 random combinations\n",
        "    cv=5,                   # 5-fold cross validation\n",
        "    scoring=\"f1_macro\",     # metric can be changed\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Evaluate Best Model\n",
        "# -------------------------------\n",
        "best_rf = random_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "# Best Parameters: {'max_depth': 3, 'n_estimators': 229}\n",
        "\n",
        "##############################################################\n",
        "# Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
        "# Best Parameters: {'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 252}\n",
        "# Accuracy: 0.8440366972477065\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oRFW4b7fCND"
      },
      "source": [
        "Cross validation 4 fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39EdLcBulxEU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/DEA_filter_AD.csv\", index_col=0)\n",
        "\n",
        "# Separate labels (first column) and features (all gene columns)\n",
        "y = data.index   # 'Normal' or 'definite AD'\n",
        "X = data.values  # all gene expression values #unfiltered\n",
        " # Cross validation\n",
        "rf = RandomForestClassifier(n_estimators=252, random_state=42, min_samples_leaf = 4, min_samples_split = 10) #'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 252\n",
        "scores = cross_val_score(rf, X, y, cv=5)  # 5-fold CV\n",
        "print(\"Mean accuracy:\", scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqBnR892qUmb"
      },
      "source": [
        "# Plotting confusion matrix and confusion heatmap plots using the results of Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_ywzBsqpXB0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Assuming y_test are true labels and y_pred are predictions\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Normal\",\"definite AD\"], yticklabels=[\"Normal\",\"definite AD\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eA-AS2upItd"
      },
      "source": [
        "DEG list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOYukq_4idju"
      },
      "outputs": [],
      "source": [
        "# sig_genes_df.to_csv('/content/drive/MyDrive/signi_genes.csv', index=False)\n",
        "\n",
        "SIGN_gene = pd.read_csv(\"/content/drive/MyDrive/signi_genes.csv\")\n",
        "print(SIGN_gene)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4acZ_ptvGw8"
      },
      "source": [
        "# Genes intersection\n",
        "From volcano genes to Random forest high ranked genes (Top 100)\n",
        "\n",
        "We got 10 common genes from DEG and RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1AKnT-LO0_o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "SIGN_gene = pd.read_csv(\"/content/drive/MyDrive/signi_genes.csv\")\n",
        "print(SIGN_gene)\n",
        "# SIGN_gene = pd.read_csv(\"/content/drive/MyDrive/signi_genes.csv\")\n",
        "importance_annot = pd.read_csv(\"/content/drive/MyDrive/gene_ranking_randomforest.csv\")\n",
        "importance_annot_top = importance_annot.head(int(100)) # for top 1% write int(22283 * 0.01)\n",
        "# Get unique genes from each dataframe\n",
        "genes1 = set(SIGN_gene['Gene Volcano'].dropna().unique())\n",
        "genes2 = set(importance_annot_top['Gene Symbol'].dropna().unique())\n",
        "\n",
        "# Find common genes\n",
        "common_genes = sorted(genes1.intersection(genes2))\n",
        "\n",
        "print(f\"Number of common genes: {len(common_genes)}\")\n",
        "print(common_genes[:20])  # Preview first 20\n",
        "\n",
        "# list to datafram\n",
        "common_genes_df = pd.DataFrame(common_genes, columns=[\"DEG_and_RF\"])\n",
        "# Save to CSV\n",
        "common_genes_df.to_csv(\"/content/drive/MyDrive/DEG_and_RF.csv\", index=False)\n",
        "print(common_genes_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuXvId43LhOk"
      },
      "source": [
        "# Support Vector Machine Analysis\n",
        "**To filter out more reliable gene biomarkers**\n",
        "\n",
        "Using SVM as a disease condition predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ2ZT1TMywi8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "############################################\n",
        "\n",
        "# DEA_data = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_DEA_data.csv\", index_col=0)\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/FILENAME.csv\", index_col=0)\n",
        "# Keep only samples from 'Normal' and 'Definite AD'\n",
        "# DEA_filter_AD = DEA_data[DEA_data.index.isin(['Normal', 'definite AD'])]\n",
        "DEA_filter_AD = pd.read_csv(\"/content/drive/MyDrive/DEA_filter_AD.csv\",index_col=0)\n",
        "\n",
        "DEA_filter_AD.head()\n",
        "\n",
        "###########################################\n",
        "\n",
        "# Assuming we already have DEA_filter_AD\n",
        "X = DEA_filter_AD.values          # expression matrix\n",
        "y = DEA_filter_AD.index.values    # labels: 'Normal' or 'definite AD'\n",
        "\n",
        "# gene_names = DEA_filter_AD.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W5cH5CyMk4M"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize (important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Linear SVM\n",
        "# C (Regularization Parameter)\n",
        "# Controls how much SVM tolerates misclassification.\n",
        "# High C (e.g., 100) → Model tries to classify every point correctly → tighter boundaries, risk of overfitting.\n",
        "# Low C (e.g., 0.01) → Allows some misclassifications → smoother boundary, better generalization.\n",
        "clf = SVC(kernel=\"linear\", C=50, class_weight=\"balanced\", random_state=42)\n",
        "# clf = SVC(kernel=\"linear\", C=1, probability=True, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Test Accuracy:\", clf.score(X_test, y_test))\n",
        "# Test Accuracy: 0.7431192660550459"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2mTEUs73tv4"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "scores = cross_val_score(clf, scaler.fit_transform(X), y, cv=5)\n",
        "print(\"Mean CV Accuracy:\", scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5C4739sj9jP"
      },
      "source": [
        "Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0FGZWjIj83Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (SVM)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAVaZDC2PbHq"
      },
      "source": [
        "# Genes from SVM\n",
        "\n",
        "Ranking genes on the basis of their weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUrR5ZNgPFZT"
      },
      "outputs": [],
      "source": [
        "# Extract weights from linear SVM\n",
        "coef = np.ravel(clf.coef_)\n",
        "\n",
        "# Gene rankings\n",
        "gene_importance_SVM = pd.DataFrame({\n",
        "    \"Gene\": gene_names,\n",
        "    \"Weight\": coef,\n",
        "    \"AbsWeight\": np.abs(coef)\n",
        "}).sort_values(by=\"AbsWeight\", ascending=False)\n",
        "\n",
        "# print(gene_importance_SVM)\n",
        "##############################################################\n",
        "# Annotation data\n",
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "# print(annot)\n",
        "# Keep only relevant columns\n",
        "annot = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "# So after this line, annot is a slimmed-down dataframe with just these three columns.\n",
        "\n",
        "# importance_annot = gene_importances.merge(\n",
        "#     annot,\n",
        "#     left_on=\"Gene\",   # from gene_importances\n",
        "#     right_on=\"ID\",    # from annotation\n",
        "#     how=\"left\"\n",
        "# )\n",
        "# The merge is done with:\n",
        "# left_on=\"Gene\" → use the \"Gene\" column from gene_importances\n",
        "# right_on=\"ID\" → match with \"ID\" column from annot\n",
        "# how=\"left\" → keep all rows from gene_importances even if some genes don’t have a matching annotation. For those without a match, the \"Gene Symbol\" and \"ENTREZ_GENE_ID\" will be NaN.\n",
        "importance_annot_SVM = gene_importance_SVM.merge(\n",
        "    annot,\n",
        "    left_on=\"Gene\",   # from gene_importances\n",
        "    right_on=\"ID\",    # from annotation\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Save also\n",
        "importance_annot_SVM.to_csv(\"/content/drive/MyDrive/gene_importance_SVM.csv\", index=False)\n",
        "\n",
        "print(\"Top 50 important genes:\")\n",
        "print(importance_annot_SVM.head(50))\n",
        "############################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-N1DuoUkV4Y"
      },
      "source": [
        "# **Gene intersection from DEG and SVM**\n",
        "Intersection of high ranked genes from SVM (Top 100)\n",
        "We got 7 intersected genes (now 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b40VjvAUSKJ"
      },
      "source": [
        "['ADM', 'C10orf10', 'DDX17', 'HBA1 /// HBA2', 'HBB', 'PSPH', 'VEGFA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxoHOB9cSEUW"
      },
      "outputs": [],
      "source": [
        "# Top 100 genes\n",
        "import pandas as pd\n",
        "SIGN_gene = pd.read_csv(\"/content/drive/MyDrive/signi_genes.csv\")\n",
        "# top_SVM_genes = gene_importance_SVM.head(10)\n",
        "\n",
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "# Keep only relevant columns\n",
        "annot = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "#############################################################\n",
        "\n",
        "#The merge is done with:\n",
        "# left_on=\"Gene\" → use the \"Gene\" column from gene_importances\n",
        "# right_on=\"ID\" → match with \"ID\" column from annot\n",
        "# how=\"left\" → keep all rows from gene_importances even if some genes don’t have a matching annotation.\n",
        "# For those without a match, the \"Gene Symbol\" and \"ENTREZ_GENE_ID\" will be NaN.\n",
        "\n",
        "# SIGN_gene = pd.read_csv(\"/content/drive/MyDrive/signi_genes.csv\")\n",
        "gene_importance_SVM = pd.read_csv(\"/content/drive/MyDrive/gene_importance_SVM.csv\")\n",
        "gene_importance_SVM_top = gene_importance_SVM.head(int(100)) # for top 1% write int(22283 * 0.01)\n",
        "# Get unique genes from each dataframe\n",
        "\n",
        "genes11 = set(SIGN_gene['Gene Volcano'].dropna().unique())\n",
        "genes22 = set(gene_importance_SVM_top['Gene Symbol'].dropna().unique())\n",
        "# print(genes11)\n",
        "# print(genes22)\n",
        "# Find common genes\n",
        "common_genes_SVM = sorted(genes11.intersection(genes22))\n",
        "# list to datafram\n",
        "common_genes_SVM_df = pd.DataFrame(common_genes_SVM, columns=[\"DEG_and_SVM\"])\n",
        "# Save to CSV\n",
        "common_genes_SVM_df.to_csv(\"/content/drive/MyDrive/DEG_and_SVM.csv\", index=False)\n",
        "# common_genes\n",
        "print(f\"Number of common genes: {len(common_genes_SVM)}\")\n",
        "print(common_genes_SVM_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzI3sVCSJGYt"
      },
      "source": [
        "# **SVM-RFE**\n",
        "**(Another method to find high ranked genes)**\n",
        "\n",
        "Previus SVM could not be improved more!\n",
        "SVM-RFE (Recursive Feature Elimination), the workflow would be different:\n",
        "Start with all genes (or after filtering by variance, if dataset is too large).\n",
        "Train an SVM (usually linear kernel for interpretability).\n",
        "Rank features by their weights (importance).\n",
        "Recursively eliminate the least important features.\n",
        "Repeat until the desired number of genes is selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E62QRLg5JL-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import RFE, VarianceThreshold\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load Data\n",
        "# --------------------------\n",
        "DEA_filter_AD = pd.read_csv(\"/content/drive/MyDrive/DEA_filter_AD.csv\", index_col=0)\n",
        "\n",
        "# Extract X (features) and y (labels)\n",
        "X1 = DEA_filter_AD.values           # expression matrix\n",
        "y = DEA_filter_AD.index.values      # labels: 'Normal' or 'definite AD'\n",
        "gene_names = DEA_filter_AD.columns  # original gene IDs\n",
        "\n",
        "print(\"Original shape:\", X1.shape)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Filter by variance\n",
        "# --------------------------\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "X = selector.fit_transform(X1)\n",
        "\n",
        "# Update gene names after filtering\n",
        "selected_genes = gene_names[selector.get_support()]\n",
        "\n",
        "print(\"After variance filtering:\", X.shape)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Run Recursive Feature Elimination (SVM-RFE)\n",
        "# --------------------------\n",
        "svm = SVC(kernel=\"linear\", C=1, random_state=42)\n",
        "rfe = RFE(estimator=svm, n_features_to_select=100, step=0.1)  # Select top 20 genes\n",
        "rfe.fit(X, y)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Rank features\n",
        "# --------------------------\n",
        "ranking = pd.DataFrame({\n",
        "    \"Gene\": selected_genes,\n",
        "    \"Rank\": rfe.ranking_\n",
        "}).sort_values(by=\"Rank\")\n",
        "\n",
        "print(\"Top 20 genes from SVM-RFE:\")\n",
        "print(ranking.head(100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BwrrgmehAXx"
      },
      "outputs": [],
      "source": [
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "# print(annot)\n",
        "# Keep only relevant columns\n",
        "annot = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "# So after this line, annot is a slimmed-down dataframe with just these three columns.\n",
        "\n",
        "# importance_annot = gene_importances.merge(\n",
        "#     annot,\n",
        "#     left_on=\"Gene\",   # from gene_importances\n",
        "#     right_on=\"ID\",    # from annotation\n",
        "#     how=\"left\"\n",
        "# )\n",
        "# The merge is done with:\n",
        "# left_on=\"Gene\" → use the \"Gene\" column from gene_importances\n",
        "# right_on=\"ID\" → match with \"ID\" column from annot\n",
        "# how=\"left\" → keep all rows from gene_importances even if some genes don’t have a matching annotation.\n",
        "# For those without a match, the \"Gene Symbol\" and \"ENTREZ_GENE_ID\" will be NaN.\n",
        "importance_annot_SVM_RFE = ranking.merge(\n",
        "    annot,\n",
        "    left_on=\"Gene\",   # from gene_importances\n",
        "    right_on=\"ID\",    # from annotation\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Save also\n",
        "importance_annot_SVM_RFE.to_csv(\"/content/drive/MyDrive/gene_importance_SVM.csv\", index=False)\n",
        "\n",
        "print(\"Top 20 important genes:\")\n",
        "print(importance_annot_SVM_RFE.head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYUr0smzgF8J"
      },
      "source": [
        "# Gene intersection from DEG and SVM-RFE\n",
        "\n",
        "Here we got 8 intersected genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IHasUsyQGNl"
      },
      "outputs": [],
      "source": [
        "# Top 20 genes\n",
        "import pandas as pd\n",
        "SIGN_gene = pd.read_csv(\"/content/drive/MyDrive/signi_genes.csv\")\n",
        "# top_SVM_genes = gene_importance_SVM.head(10)\n",
        "print()\n",
        "annot = pd.read_csv(\"/content/drive/MyDrive/GSE84422_GPL96_Annotation_Data.csv\")\n",
        "# Keep only relevant columns\n",
        "annot = annot[[\"ID\", \"Gene Symbol\", \"ENTREZ_GENE_ID\"]]\n",
        "#############################################################\n",
        "importance_annot_SVM_RFE = pd.read_csv(\"/content/drive/MyDrive/gene_importance_SVM.csv\")\n",
        "\n",
        "# gene_importance_SVM = pd.read_csv(\"/content/drive/MyDrive/gene_importance_SVM.csv\")\n",
        "# gene_importance_SVM_top = gene_importance_SVM.head(int(100)) # for top 1% write int(22283 * 0.01)\n",
        "# Get unique genes from each dataframe\n",
        "\n",
        "genes11 = set(SIGN_gene['Gene Volcano'].dropna().unique())\n",
        "genes22 = set(importance_annot_SVM_RFE.head(100)['Gene Symbol'].dropna().unique())\n",
        "# print(genes11)\n",
        "# print(genes22)\n",
        "# Find common genes\n",
        "common_genes_SVM_RFE = sorted(genes11.intersection(genes22))\n",
        "# common_genes\n",
        "print(f\"Number of common genes: {len(common_genes_SVM_RFE)}\")\n",
        "# list to dataframe\n",
        "common_genes_SVM_RFE_df = pd.DataFrame(common_genes_SVM, columns=[\"DEG_and_SVMRFE\"])\n",
        "# Save to CSV\n",
        "common_genes_SVM_RFE_df.to_csv(\"/content/drive/MyDrive/DEG_and_SVMRFE.csv\", index=False)\n",
        "print(common_genes_SVM_RFE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c5bde5c"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vPbQmQzOy3q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Updated path, assuming the notebook is inside 'Colab Notebooks' folder\n",
        "notebook_path = \"/content/drive/MyDrive/Colab Notebooks/GSE84422_Biomarker_Genes_Strip.ipynb\"\n",
        "output_path = \"/content/drive/MyDrive/abc_no_code.ipynb\"\n",
        "\n",
        "# Ensure the notebook file exists before proceeding\n",
        "if not os.path.exists(notebook_path):\n",
        "    print(f\"Error: Notebook not found at {notebook_path}. Please verify the filename and path.\")\n",
        "else:\n",
        "    !jupyter nbconvert --to notebook --ClearOutputPreprocessor.enabled=True \\\n",
        "    --TemplateExporter.exclude_input=True \\\n",
        "    --output=\"{output_path}\" \"{notebook_path}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34c30cc6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1y1RxdzOuWPr0LW6Yy0md6ieyL2NoNk9G",
      "authorship_tag": "ABX9TyPduiPg8c2W0WWjSqDCrz34"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}